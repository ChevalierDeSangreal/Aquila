#!/usr/bin/env python
# coding: utf-8

import os
import sys

# ==================== GPU Configuration ====================
os.environ['CUDA_VISIBLE_DEVICES'] = '1'
os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/local/cuda'

import time
import jax
import jax.numpy as jnp
import numpy as np
import pickle
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle
from mpl_toolkits.mplot3d import Axes3D

# Add parent directory to path for imports
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../..'))

from aquila.envs.target_trackVer11 import TrackEnvVer11
from aquila.envs.wrappers import MinMaxObservationWrapper, NormalizeActionWrapper
from aquila.modules.mlp import MLP
from aquila.utils.trajectory_utils import (
    TrajectoryGenerator,
    CircularTrajectory,
    create_trajectory
)


def load_trained_policy(checkpoint_path):
    """åŠ è½½è®­ç»ƒå¥½çš„ç­–ç•¥å‚æ•°"""
    print(f"Loading policy from: {checkpoint_path}")
    
    with open(checkpoint_path, 'rb') as f:
        data = pickle.load(f)
    
    if isinstance(data, dict):
        params = data['params']
        env_config = data.get('env_config', {})
        final_loss = data.get('final_loss', 'Unknown')
        training_epochs = data.get('training_epochs', 'Unknown')
        action_repeat = data.get('action_repeat', 1)
        buffer_size = data.get('action_obs_buffer_size', 1)
    else:
        # å…¼å®¹æ—§æ ¼å¼
        params = data
        env_config = {}
        final_loss = 'Unknown'
        training_epochs = 'Unknown'
        action_repeat = 1
        buffer_size = 1
    
    print("âœ… Policy parameters loaded successfully!")
    print(f"   Final loss: {final_loss}")
    print(f"   Training epochs: {training_epochs}")
    print(f"   Action repeat: {action_repeat}")
    print(f"   Action-obs buffer size: {buffer_size}")
    
    return params, env_config, action_repeat, buffer_size


def compute_distance_to_boundary(position, boundary_half_x, boundary_half_y, boundary_z):
    """è®¡ç®—ä½ç½®åˆ°è¾¹ç•Œçš„æœ€å°è·ç¦»ï¼ˆæ­£å€¼è¡¨ç¤ºåœ¨è¾¹ç•Œå†…ï¼Œè´Ÿå€¼è¡¨ç¤ºè¶…å‡ºè¾¹ç•Œï¼‰"""
    dist_to_px = boundary_half_x - position[0]  # è·ç¦»+Xé¢
    dist_to_nx = position[0] + boundary_half_x  # è·ç¦»-Xé¢
    dist_to_py = boundary_half_y - position[1]  # è·ç¦»+Yé¢
    dist_to_ny = position[1] + boundary_half_y  # è·ç¦»-Yé¢
    dist_to_pz = 0.0 - position[2]  # è·ç¦»+Zé¢ï¼ˆåœ°é¢ï¼Œz=0ï¼‰
    dist_to_nz = position[2] + boundary_z  # è·ç¦»-Zé¢ï¼ˆé¡¶éƒ¨ï¼Œz=-boundary_zï¼‰
    
    min_distance = min(dist_to_px, dist_to_nx, dist_to_py, dist_to_ny, dist_to_pz, dist_to_nz)
    return min_distance


def ensure_trajectory_within_boundary(trajectory: CircularTrajectory,
                                     boundary_half_x: float,
                                     boundary_half_y: float,
                                     boundary_z: float,
                                     safety_margin: float = 0.5) -> CircularTrajectory:
    """
    ç¡®ä¿åœ†å½¢è½¨è¿¹åœ¨è¾¹ç•Œå†…ï¼ˆè€ƒè™‘å®‰å…¨è¾¹è·ï¼‰
    
    Args:
        trajectory: åŸå§‹åœ†å½¢è½¨è¿¹ç”Ÿæˆå™¨
        boundary_half_x: Xæ–¹å‘è¾¹ç•Œçš„ä¸€åŠï¼ˆNEDåæ ‡ç³»ï¼‰
        boundary_half_y: Yæ–¹å‘è¾¹ç•Œçš„ä¸€åŠ
        boundary_z: Zæ–¹å‘è¾¹ç•Œï¼ˆä»-boundary_zåˆ°0ï¼‰
        safety_margin: å®‰å…¨è¾¹è·ï¼ˆç±³ï¼‰
        
    Returns:
        è°ƒæ•´åçš„è½¨è¿¹ç”Ÿæˆå™¨ï¼ˆæ–°å®ä¾‹ï¼Œä¸ä¿®æ”¹åŸå®ä¾‹ï¼‰
    """
    # å¯¹äºåœ†å½¢è½¨è¿¹ï¼Œç¡®ä¿åœ†å¿ƒä½ç½®å’ŒåŠå¾„çš„ç»„åˆä½¿å¾—æ•´ä¸ªåœ†éƒ½åœ¨è¾¹ç•Œå†…
    # åœ†çš„ä»»ä½•ç‚¹éƒ½åœ¨: [center_x Â± radius, center_y Â± radius]
    
    # å…ˆç¡®å®šåœ†å¿ƒä½ç½®çš„èŒƒå›´ï¼ˆè€ƒè™‘åŠå¾„ï¼‰
    # å¦‚æœåœ†å¿ƒä½ç½®è¶…å‡ºè¾¹ç•Œï¼Œå…ˆè°ƒæ•´å®ƒï¼ˆå±…ä¸­ï¼‰
    center_x = 0.0  # å±…ä¸­
    center_y = 0.0  # å±…ä¸­
    
    # è®¡ç®—æœ€å¤§å…è®¸åŠå¾„ï¼ˆåŸºäºå±…ä¸­çš„åœ†å¿ƒä½ç½®ï¼‰
    max_radius_x = boundary_half_x - safety_margin
    max_radius_y = boundary_half_y - safety_margin
    max_radius = min(max_radius_x, max_radius_y)
    
    # å¦‚æœåŠå¾„å¤ªå¤§ï¼Œç¼©å°å®ƒ
    adjusted_radius = min(trajectory.radius, max_radius)
    
    # å¦‚æœåŠå¾„å¤ªå°ï¼Œä½¿ç”¨ä¸€ä¸ªåˆç†çš„æœ€å°å€¼
    if adjusted_radius < 0.5:
        adjusted_radius = min(1.0, max_radius)
    
    # ç¡®ä¿zåæ ‡åœ¨è¾¹ç•Œå†…ï¼ˆå±…ä¸­åœ¨é«˜åº¦çš„ä¸€åŠï¼‰
    center_z = np.clip(
        trajectory.center_z,
        -boundary_z + safety_margin + 1.0,  # ç¡®ä¿æœ‰è¶³å¤Ÿç©ºé—´
        -safety_margin - 1.0
    )
    
    # å¦‚æœcenter_zæ²¡æœ‰è®¾ç½®æˆ–è¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨è¾¹ç•Œä¸­é—´å€¼
    if center_z > -safety_margin or center_z < -boundary_z + safety_margin:
        center_z = -boundary_z * 0.5  # åœ¨è¾¹ç•Œé«˜åº¦çš„ä¸€åŠå¤„
    
    # åˆ›å»ºæ–°çš„åœ†å½¢è½¨è¿¹
    return CircularTrajectory(
        center=(float(center_x), float(center_y), float(center_z)),
        radius=float(adjusted_radius),
        num_circles=trajectory.num_circles,
        ramp_up_time=trajectory.ramp_up_time,
        ramp_down_time=trajectory.ramp_down_time,
        circle_duration=trajectory.circle_duration,
        init_phase=trajectory.init_phase,
        max_speed=trajectory.max_speed
    )


def run_test_episode(env, policy_apply, params, key, action_repeat, buffer_size, 
                     trajectory: CircularTrajectory = None, verbose=False):
    """
    è¿è¡Œä¸€ä¸ªæµ‹è¯•episodeï¼Œè®°å½•è·Ÿè¸ªå’Œè¾¹ç•Œä¿¡æ¯
    
    Args:
        env: ç¯å¢ƒå®ä¾‹
        policy_apply: ç­–ç•¥åº”ç”¨å‡½æ•°
        params: ç­–ç•¥å‚æ•°
        key: JAXéšæœºæ•°ç”Ÿæˆå™¨å¯†é’¥
        action_repeat: åŠ¨ä½œé‡å¤æ¬¡æ•°
        buffer_size: åŠ¨ä½œ-è§‚æµ‹ç¼“å†²åŒºå¤§å°
        trajectory: åœ†å½¢è½¨è¿¹ç”Ÿæˆå™¨ï¼Œå¦‚æœæä¾›åˆ™è¦†ç›–ç¯å¢ƒçš„é»˜è®¤ç›®æ ‡è¿åŠ¨
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
    """
    # Reset environmentï¼ˆå…ˆresetè·å–åŸºæœ¬çŠ¶æ€ç»“æ„ï¼‰
    state, obs = env.reset(key)
    
    # å¦‚æœæä¾›äº†è½¨è¿¹ç”Ÿæˆå™¨ï¼Œå…ˆç¡®ä¿è½¨è¿¹åœ¨è¾¹ç•Œå†…ï¼Œç„¶åæ ¹æ®è½¨è¿¹åˆå§‹åŒ–
    if trajectory is not None:
        # 1. ç¡®ä¿è½¨è¿¹åœ¨è¾¹ç•Œå†…
        trajectory = ensure_trajectory_within_boundary(
            trajectory,
            state.boundary_half_x,
            state.boundary_half_y,
            state.boundary_z,
            safety_margin=0.5
        )
        
        # 2. è·å–è½¨è¿¹çš„åˆå§‹ä½ç½®ï¼ˆt=0æ—¶ï¼‰
        target_initial_pos, target_initial_vel = trajectory.get_state(0.0)
        target_initial_pos = np.array(target_initial_pos)  # è½¬æ¢ä¸ºnumpyä»¥ä¾¿è®¡ç®—
        target_initial_vel = jnp.array(target_initial_vel)
        
        # 3. æ ¹æ®ç›®æ ‡åˆå§‹ä½ç½®ï¼Œåˆå§‹åŒ–æ— äººæœºåœ¨ç›®æ ‡æ­£åæ–¹1må¤„ï¼ˆNEDåæ ‡ç³»ï¼Œ-Xæ–¹å‘ï¼‰
        # è¿™æ ·ç›®æ ‡å°±åœ¨æ— äººæœºæ­£å‰æ–¹1må¤„
        quad_initial_pos_np = target_initial_pos - np.array([1.0, 0.0, 0.0])  # æ­£åæ–¹1m
        
        # ç¡®ä¿æ— äººæœºä½ç½®ä¹Ÿåœ¨è¾¹ç•Œå†…ï¼ˆè€ƒè™‘å®‰å…¨è¾¹è·ï¼‰
        quad_initial_pos_np = np.clip(
            quad_initial_pos_np,
            np.array([-state.boundary_half_x + 1.0, -state.boundary_half_y + 1.0, -state.boundary_z + 1.0]),
            np.array([state.boundary_half_x - 1.0, state.boundary_half_y - 1.0, -1.0])
        )
        quad_initial_pos = jnp.array(quad_initial_pos_np)
        target_initial_pos = jnp.array(target_initial_pos)
        
        # 4. æ›´æ–°stateä¸­çš„ç›®æ ‡ä½ç½®ã€é€Ÿåº¦å’Œæ— äººæœºä½ç½®
        import dataclasses
        from aquila.objects.quadrotor_obj import QuadrotorState
        
        # æ›´æ–°æ— äººæœºçŠ¶æ€ï¼ˆä¿æŒå…¶ä»–å±æ€§ä¸å˜ï¼Œåªæ›´æ–°ä½ç½®ï¼‰
        new_quadrotor_state = dataclasses.replace(
            state.quadrotor_state,
            p=quad_initial_pos
        )
        
        # æ›´æ–°æ•´ä¸ªstate
        state = dataclasses.replace(
            state,
            quadrotor_state=new_quadrotor_state,
            target_pos=target_initial_pos,
            target_vel=target_initial_vel
        )
        
        # 5. é‡æ–°è®¡ç®—è§‚æµ‹
        obs = env._get_obs(state)
    
    # åˆå§‹åŒ–åŠ¨ä½œ-çŠ¶æ€ç¼“å†²åŒº
    obs_dim = env.observation_space.shape[0]
    action_dim = env.action_space.shape[0]
    
    # âš ï¸ é‡è¦ï¼šç¼“å†²åŒºæ ¼å¼å¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼š[action, obs]ï¼ˆå…ˆåŠ¨ä½œï¼Œåè§‚æµ‹ï¼‰
    # ç¼“å†²åŒºå½¢çŠ¶ï¼š(buffer_size, action_dim + obs_dim)
    action_obs_buffer = jnp.zeros((buffer_size, action_dim + obs_dim))
    
    # åˆå§‹åŒ–ï¼šå¡«å……é›¶åŠ¨ä½œå’Œé›¶è§‚æµ‹ï¼ˆä¸è®­ç»ƒæ—¶çš„åˆå§‹åŒ–ä¸€è‡´ï¼‰
    zero_action = jnp.zeros(action_dim)
    zero_obs = jnp.zeros(obs_dim)
    action_obs_combined = jnp.concatenate([zero_action, zero_obs])
    action_obs_buffer = jnp.tile(action_obs_combined[None, :], (buffer_size, 1))
    
    # Episode statistics
    episode_data = {
        'quad_positions': [],
        'target_positions': [],
        'distances': [],
        'boundary_distances': [],
        'rewards': [],
        'actions': [],
        'velocities': [],
        'terminated': False,
        'truncated': False,
        'num_steps': 0,
        'boundary_violations': 0,
        'min_boundary_distance': float('inf'),
    }
    
    done = False
    step_count = 0
    action = jnp.zeros(action_dim)  # åˆå§‹åŠ¨ä½œä¸ºé›¶
    action_counter = 0  # åŠ¨ä½œè®¡æ•°å™¨ï¼Œç”¨äºaction_repeat
    
    # å¦‚æœæä¾›äº†è½¨è¿¹ç”Ÿæˆå™¨ï¼Œè®°å½•è½¨è¿¹èµ·å§‹æ—¶é—´
    trajectory_start_time = 0.0 if trajectory else None
    
    while not done and step_count < env.max_steps_in_episode:
        # æ¯action_repeatæ­¥è·å–ä¸€æ¬¡æ–°åŠ¨ä½œ
        if action_counter % action_repeat == 0:
            # âš ï¸ ä¸è®­ç»ƒæ—¶ä¸€è‡´çš„é€»è¾‘ï¼š
            # æ­¥éª¤1ï¼šå…ˆç”¨ç©ºåŠ¨ä½œ+å½“å‰è§‚æµ‹æ›´æ–°ç¼“å†²åŒºï¼ˆä¸ºè·å–æ–°åŠ¨ä½œåšå‡†å¤‡ï¼‰
            action_obs_buffer_for_input = jnp.roll(action_obs_buffer, shift=-1, axis=0)
            empty_action = jnp.zeros(action_dim)
            action_obs_combined_empty = jnp.concatenate([empty_action, obs])
            action_obs_buffer_for_input = action_obs_buffer_for_input.at[-1].set(action_obs_combined_empty)
            
            # æ­¥éª¤2ï¼šå±•å¹³ç¼“å†²åŒºä½œä¸ºç½‘ç»œè¾“å…¥ï¼š[action[0], obs[0], action[1], obs[1], ...]
            network_input = action_obs_buffer_for_input.flatten()
            
            # æ­¥éª¤3ï¼šè·å–æ–°åŠ¨ä½œ
            action = policy_apply(params, network_input)
            
            # æ­¥éª¤4ï¼šç”¨è·å–åˆ°çš„æ–°åŠ¨ä½œæ›´æ–°ç¼“å†²åŒºï¼ˆç”¨äºä¸‹æ¬¡ä½¿ç”¨ï¼‰
            action_obs_buffer = jnp.roll(action_obs_buffer, shift=-1, axis=0)
            action_obs_combined_new = jnp.concatenate([action, obs])
            action_obs_buffer = action_obs_buffer.at[-1].set(action_obs_combined_new)
        
        # æ‰§è¡ŒåŠ¨ä½œ
        key, subkey = jax.random.split(key)
        transition = env.step(state, action, subkey)
        next_state, next_obs, reward, terminated, truncated, info = transition
        
        # å¦‚æœæä¾›äº†è½¨è¿¹ç”Ÿæˆå™¨ï¼Œè¦†ç›–ç›®æ ‡ä½ç½®å’Œé€Ÿåº¦
        if trajectory is not None:
            current_time = trajectory_start_time + step_count * env.dt
            traj_pos, traj_vel = trajectory.get_state(current_time)
            
            # ç¡®ä¿ç›®æ ‡ä½ç½®åœ¨è¾¹ç•Œå†…ï¼ˆè¿è¡Œæ—¶å®‰å…¨æ£€æŸ¥ï¼‰
            traj_pos_clipped = jnp.clip(
                traj_pos,
                jnp.array([-state.boundary_half_x, -state.boundary_half_y, -state.boundary_z]),
                jnp.array([state.boundary_half_x, state.boundary_half_y, 0.0])
            )
            
            # æ›´æ–°çŠ¶æ€ä¸­çš„ç›®æ ‡ä½ç½®å’Œé€Ÿåº¦
            import dataclasses
            next_state = dataclasses.replace(
                next_state,
                target_pos=traj_pos_clipped,
                target_vel=traj_vel
            )
            
            # é‡æ–°è®¡ç®—è§‚æµ‹ï¼ˆå› ä¸ºç›®æ ‡ä½ç½®æ”¹å˜äº†ï¼‰
            next_obs = env._get_obs(next_state)
        
        # è®°å½•æ•°æ®
        quad_pos = np.array(info['quad_p'])
        target_pos = np.array(info['target_p'])
        distance = np.array(info['distance_to_target'])
        
        # è®¡ç®—åˆ°è¾¹ç•Œçš„è·ç¦»
        boundary_dist = compute_distance_to_boundary(
            quad_pos, 
            state.boundary_half_x, 
            state.boundary_half_y, 
            state.boundary_z
        )
        
        episode_data['quad_positions'].append(quad_pos)
        episode_data['target_positions'].append(target_pos)
        episode_data['distances'].append(distance)
        episode_data['boundary_distances'].append(boundary_dist)
        episode_data['rewards'].append(float(reward))
        episode_data['actions'].append(np.array(action))
        episode_data['velocities'].append(np.array(info['quad_v']))
        episode_data['target_velocities'] = episode_data.get('target_velocities', [])
        episode_data['target_velocities'].append(np.array(info['target_v']))
        
        # æ£€æŸ¥è¾¹ç•Œè¿è§„ï¼ˆè¶…å‡ºè¾¹ç•Œï¼‰
        if boundary_dist < 0:
            episode_data['boundary_violations'] += 1
        
        # æ›´æ–°æœ€å°è¾¹ç•Œè·ç¦»
        episode_data['min_boundary_distance'] = min(
            episode_data['min_boundary_distance'], 
            boundary_dist
        )
        
        # æ›´æ–°çŠ¶æ€å’Œè§‚æµ‹
        state = next_state
        obs = next_obs  # æ›´æ–°obsä»¥ä¾¿ä¸‹æ¬¡è·å–åŠ¨ä½œæ—¶ä½¿ç”¨
        done = terminated or truncated
        step_count += 1
        action_counter += 1
        
        if verbose and step_count % 100 == 0:
            print(f"  Step {step_count}: Distance={distance:.3f}m, Boundary={boundary_dist:.3f}m, Reward={reward:.3f}")
    
    episode_data['terminated'] = bool(terminated)
    episode_data['truncated'] = bool(truncated)
    episode_data['num_steps'] = step_count
    
    return episode_data


def visualize_episode(episode_data, boundary_half_x, boundary_half_y, boundary_z, episode_idx=0, save_path=None):
    """å¯è§†åŒ–å•ä¸ªepisodeçš„ç»“æœ"""
    fig = plt.figure(figsize=(24, 16))
    
    # 1. 3Dè½¨è¿¹å›¾
    ax1 = fig.add_subplot(3, 3, 1, projection='3d')
    quad_positions = np.array(episode_data['quad_positions'])
    target_positions = np.array(episode_data['target_positions'])
    
    ax1.plot(quad_positions[:, 0], quad_positions[:, 1], quad_positions[:, 2], 
             'b-', label='Quadrotor', linewidth=2, alpha=0.7)
    ax1.plot(target_positions[:, 0], target_positions[:, 1], target_positions[:, 2], 
             'r--', label='Target', linewidth=2, alpha=0.7)
    
    # ç»˜åˆ¶è¾¹ç•Œæ¡†ï¼ˆNEDåæ ‡ç³»ï¼šzèŒƒå›´[-boundary_z, 0]ï¼‰
    from mpl_toolkits.mplot3d.art3d import Poly3DCollection
    vertices = [
        [-boundary_half_x, -boundary_half_y, -boundary_z],
        [boundary_half_x, -boundary_half_y, -boundary_z],
        [boundary_half_x, boundary_half_y, -boundary_z],
        [-boundary_half_x, boundary_half_y, -boundary_z],
        [-boundary_half_x, -boundary_half_y, 0],
        [boundary_half_x, -boundary_half_y, 0],
        [boundary_half_x, boundary_half_y, 0],
        [-boundary_half_x, boundary_half_y, 0],
    ]
    
    # ç»˜åˆ¶è¾¹ç•Œæ¡†çš„è¾¹
    edges = [
        [vertices[0], vertices[1], vertices[2], vertices[3]],  # é¡¶é¢
        [vertices[4], vertices[5], vertices[6], vertices[7]],  # åº•é¢
        [vertices[0], vertices[4]], [vertices[1], vertices[5]],  # å‚ç›´è¾¹
        [vertices[2], vertices[6]], [vertices[3], vertices[7]],
    ]
    
    for edge in edges[:2]:
        poly = Poly3DCollection([edge], alpha=0.1, facecolor='gray', edgecolor='black', linewidth=2)
        ax1.add_collection3d(poly)
    
    ax1.set_xlabel('X (North) [m]')
    ax1.set_ylabel('Y (East) [m]')
    ax1.set_zlabel('Z (Down) [m]')
    ax1.set_title(f'Episode {episode_idx}: 3D Trajectory (NED frame)')
    ax1.legend()
    ax1.grid(True)
    
    # è®¾ç½®ç›¸ç­‰çš„åæ ‡è½´æ¯”ä¾‹
    max_range = max(boundary_half_x, boundary_half_y, boundary_z)
    ax1.set_xlim([-max_range, max_range])
    ax1.set_ylim([-max_range, max_range])
    ax1.set_zlim([-max_range, max_range])
    
    # 2. XYå¹³é¢æŠ•å½±ï¼ˆä¿¯è§†å›¾ï¼‰
    ax2 = fig.add_subplot(3, 3, 2)
    ax2.plot(quad_positions[:, 0], quad_positions[:, 1], 'b-', label='Quadrotor', linewidth=2, alpha=0.7)
    ax2.plot(target_positions[:, 0], target_positions[:, 1], 'r--', label='Target', linewidth=2, alpha=0.7)
    
    # ç»˜åˆ¶è¾¹ç•Œ
    boundary_rect = Rectangle(
        (-boundary_half_x, -boundary_half_y), 
        2 * boundary_half_x, 
        2 * boundary_half_y,
        fill=False, edgecolor='black', linewidth=2, linestyle='--'
    )
    ax2.add_patch(boundary_rect)
    
    ax2.set_xlabel('X (North) [m]')
    ax2.set_ylabel('Y (East) [m]')
    ax2.set_title(f'Episode {episode_idx}: Top View (XY plane)')
    ax2.legend()
    ax2.grid(True)
    ax2.axis('equal')
    
    # 3. è·Ÿè¸ªè·ç¦»éšæ—¶é—´å˜åŒ–
    ax3 = fig.add_subplot(3, 3, 3)
    distances = np.array(episode_data['distances'])
    ax3.plot(distances, 'b-', linewidth=2)
    ax3.axhline(y=1.0, color='r', linestyle='--', label='Target Distance (1m)')
    ax3.axhline(y=1.3, color='orange', linestyle=':', label='Acceptable Range (Â±30cm)')
    ax3.axhline(y=0.7, color='orange', linestyle=':')
    ax3.set_xlabel('Step')
    ax3.set_ylabel('Distance to Target [m]')
    ax3.set_title(f'Episode {episode_idx}: Tracking Distance')
    ax3.legend()
    ax3.grid(True)
    
    # 4. åˆ°è¾¹ç•Œçš„è·ç¦»éšæ—¶é—´å˜åŒ–
    ax4 = fig.add_subplot(3, 3, 4)
    boundary_distances = np.array(episode_data['boundary_distances'])
    ax4.plot(boundary_distances, 'g-', linewidth=2)
    ax4.axhline(y=0, color='r', linestyle='--', label='Boundary')
    ax4.axhline(y=1.0, color='orange', linestyle=':', label='Warning Zone (1m)')
    ax4.set_xlabel('Step')
    ax4.set_ylabel('Distance to Boundary [m]')
    ax4.set_title(f'Episode {episode_idx}: Boundary Distance (negative=violation)')
    ax4.legend()
    ax4.grid(True)
    
    # 5. å¥–åŠ±éšæ—¶é—´å˜åŒ–
    ax5 = fig.add_subplot(3, 3, 5)
    rewards = np.array(episode_data['rewards'])
    ax5.plot(rewards, 'purple', linewidth=2)
    ax5.set_xlabel('Step')
    ax5.set_ylabel('Reward')
    ax5.set_title(f'Episode {episode_idx}: Rewards')
    ax5.grid(True)
    
    # 6. ç›®æ ‡ç‰©ä½“é€Ÿåº¦éšæ—¶é—´å˜åŒ–
    ax6 = fig.add_subplot(3, 3, 6)
    target_velocities = np.array(episode_data.get('target_velocities', []))
    if len(target_velocities) > 0:
        target_speed = np.linalg.norm(target_velocities, axis=1)
        ax6.plot(target_speed, 'r-', linewidth=2, label='Target Speed')
        ax6.axhline(y=1.0, color='orange', linestyle='--', linewidth=1, label='Max Speed (1 m/s)')
        ax6.set_xlabel('Step')
        ax6.set_ylabel('Speed [m/s]')
        ax6.set_title(f'Episode {episode_idx}: Target Speed')
        ax6.legend()
        ax6.grid(True)
        ax6.set_ylim(bottom=0)
    
    # 7. æ— äººæœºé€Ÿåº¦éšæ—¶é—´å˜åŒ–
    ax7 = fig.add_subplot(3, 3, 7)
    velocities = np.array(episode_data['velocities'])
    quad_speed = np.linalg.norm(velocities, axis=1)
    ax7.plot(quad_speed, 'b-', linewidth=2, label='Quad Speed')
    ax7.set_xlabel('Step')
    ax7.set_ylabel('Speed [m/s]')
    ax7.set_title(f'Episode {episode_idx}: Quadrotor Speed')
    ax7.legend()
    ax7.grid(True)
    ax7.set_ylim(bottom=0)
    
    # 8. ç›®æ ‡é€Ÿåº¦å‘é‡ï¼ˆ3ä¸ªåˆ†é‡ï¼‰
    ax8 = fig.add_subplot(3, 3, 8)
    if len(target_velocities) > 0:
        ax8.plot(target_velocities[:, 0], 'r-', alpha=0.7, label='Vx (North)', linewidth=1.5)
        ax8.plot(target_velocities[:, 1], 'g-', alpha=0.7, label='Vy (East)', linewidth=1.5)
        ax8.plot(target_velocities[:, 2], 'b-', alpha=0.7, label='Vz (Down)', linewidth=1.5)
        ax8.set_xlabel('Step')
        ax8.set_ylabel('Velocity [m/s]')
        ax8.set_title(f'Episode {episode_idx}: Target Velocity Components')
        ax8.legend()
        ax8.grid(True)
    
    # 9. ç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬
    ax9 = fig.add_subplot(3, 3, 9)
    ax9.axis('off')
    
    mean_distance = np.mean(distances)
    std_distance = np.std(distances)
    min_distance = np.min(distances)
    max_distance = np.max(distances)
    mean_reward = np.mean(rewards)
    total_reward = np.sum(rewards)
    min_boundary_dist = episode_data['min_boundary_distance']
    boundary_violations = episode_data['boundary_violations']
    
    # è®¡ç®—è·Ÿè¸ªæˆåŠŸç‡ï¼ˆè·ç¦»åœ¨ç›®æ ‡Â±30cmå†…çš„æ¯”ä¾‹ï¼‰
    tracking_success_rate = np.mean(np.abs(distances - 1.0) < 0.3) * 100
    
    # è®¡ç®—ç›®æ ‡é€Ÿåº¦ç»Ÿè®¡
    target_velocities = np.array(episode_data.get('target_velocities', []))
    if len(target_velocities) > 0:
        target_speed = np.linalg.norm(target_velocities, axis=1)
        mean_target_speed = np.mean(target_speed)
        max_target_speed = np.max(target_speed)
    else:
        mean_target_speed = 0.0
        max_target_speed = 0.0
    
    stats_text = f"""
    Episode {episode_idx} Statistics:
    
    Steps: {episode_data['num_steps']}
    Terminated: {episode_data['terminated']}
    Truncated: {episode_data['truncated']}
    
    Tracking Performance:
    â€¢ Mean Distance: {mean_distance:.3f} m
    â€¢ Std Distance: {std_distance:.3f} m
    â€¢ Min Distance: {min_distance:.3f} m
    â€¢ Max Distance: {max_distance:.3f} m
    â€¢ Success Rate (Â±30cm): {tracking_success_rate:.1f}%
    
    Boundary Avoidance:
    â€¢ Min Boundary Dist: {min_boundary_dist:.3f} m
    â€¢ Boundary Violations: {boundary_violations}
    â€¢ Violation Rate: {boundary_violations/episode_data['num_steps']*100:.1f}%
    
    Target Motion:
    â€¢ Mean Speed: {mean_target_speed:.3f} m/s
    â€¢ Max Speed: {max_target_speed:.3f} m/s
    
    Rewards:
    â€¢ Mean Reward: {mean_reward:.3f}
    â€¢ Total Reward: {total_reward:.3f}
    """
    
    ax9.text(0.1, 0.5, stats_text, fontsize=10, verticalalignment='center',
             family='monospace', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"  Visualization saved to: {save_path}")
    
    return fig


def main():
    # ==================== Configuration ====================
    print(f"JAX devices: {jax.devices()}")
    print(f"JAX device count: {jax.device_count()}")
    
    # ==================== Circular Trajectory Setup ====================
    # åˆ›å»ºå±…ä¸­çš„åœ†å½¢è½¨è¿¹
    # å‚æ•°ä¼šåœ¨ç¯å¢ƒåˆ›å»ºåæ ¹æ®è¾¹ç•Œè¿›è¡Œè°ƒæ•´
    trajectory = create_trajectory(
        'circular',
        center=(0.0, 0.0, -2.0),  # ä¸´æ—¶ä¸­å¿ƒï¼Œä¼šæ ¹æ®è¾¹ç•Œè°ƒæ•´
        radius=2.0,                # åŠå¾„ï¼ˆç±³ï¼‰ï¼Œä¼šæ ¹æ®è¾¹ç•Œè°ƒæ•´
        num_circles=2,             # åœ†åœˆæ•°é‡
        ramp_up_time=3.0,          # åŠ é€Ÿæ—¶é—´ï¼ˆç§’ï¼‰
        ramp_down_time=3.0,        # å‡é€Ÿæ—¶é—´ï¼ˆç§’ï¼‰
        circle_duration=20.0,      # å•åœˆåä¹‰æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
        init_phase=0.0,            # åˆå§‹ç›¸ä½ï¼ˆå¼§åº¦ï¼‰
        max_speed=1.0              # æœ€å¤§é€Ÿåº¦é™åˆ¶ï¼ˆm/sï¼‰
    )
    
    print(f"\n{'='*60}")
    print(f"Circular Trajectory Configuration:")
    print(f"{'='*60}")
    traj_info = trajectory.get_info()
    for key, value in traj_info.items():
        print(f"  {key}: {value}")
    print(f"Note: Trajectory will be adjusted to fit within boundaries")
    print(f"{'='*60}\n")
    
    # Load trained policy
    policy_file = 'aquila/param/trackVer11_policy.pkl'
    
    if not os.path.exists(policy_file):
        print(f"âŒ Error: Policy file not found: {policy_file}")
        print("   Please train the model first using train_trackVer11.py")
        return
    
    params, env_config, action_repeat, buffer_size = load_trained_policy(policy_file)
    
    # ==================== Environment Setup ====================
    # Create env with same configuration as training
    env = TrackEnvVer11(
        max_steps_in_episode=env_config.get('max_steps_in_episode', 1000),
        dt=env_config.get('dt', 0.01),
        delay=env_config.get('delay', 0.03),
        omega_std=0.1,
        action_penalty_weight=env_config.get('action_penalty_weight', 0.5),
        target_height=env_config.get('target_height', 2.0),
        target_init_distance_min=env_config.get('target_init_distance_min', 0.5),
        target_init_distance_max=env_config.get('target_init_distance_max', 1.5),
        target_speed_max=env_config.get('target_speed_max', 2.0),
        reset_distance=env_config.get('reset_distance', 100.0),
        max_speed=env_config.get('max_speed', 20.0),
        boundary_x=env_config.get('boundary_x', 10.0),
        boundary_y=env_config.get('boundary_y', 10.0),
        boundary_z=env_config.get('boundary_z', 10.0),
        boundary_penalty_distance=env_config.get('boundary_penalty_distance', 1.0),
        boundary_penalty_max=env_config.get('boundary_penalty_max', 100.0),
        thrust_to_weight_min=1.2,
        thrust_to_weight_max=5.0,
        disturbance_mag=0.0,  # æµ‹è¯•æ—¶å…³é—­æ‰°åŠ¨
    )
    
    # Apply wrappers
    env = MinMaxObservationWrapper(env)
    env = NormalizeActionWrapper(env)
    
    # ==================== Model Setup ====================
    obs_dim = env.observation_space.shape[0]
    action_dim = env.action_space.shape[0]
    input_dim = buffer_size * (obs_dim + action_dim)
    
    policy = MLP([input_dim, 128, 128, action_dim], initial_scale=0.2)
    
    print(f"\n{'='*60}")
    print(f"Test Configuration:")
    print(f"{'='*60}")
    print(f"Environment: TrackEnvVer11 (with boundary constraints)")
    print(f"Observation dimension: {obs_dim}")
    print(f"Action dimension: {action_dim}")
    print(f"Action repeat: {action_repeat}")
    print(f"Action-obs buffer size: {buffer_size}")
    print(f"Input dimension: {input_dim}")
    print(f"Boundary: x=[{-env.boundary_half_x:.1f}, {env.boundary_half_x:.1f}], "
          f"y=[{-env.boundary_half_y:.1f}, {env.boundary_half_y:.1f}], "
          f"z=[{-env.boundary_z:.1f}, 0.0]")
    print(f"Disturbance: DISABLED (for testing)")
    print(f"{'='*60}\n")
    
    # ==================== Run Test Episodes ====================
    num_test_episodes = 1
    print(f"Running {num_test_episodes} test episode...\n")
    
    key = jax.random.key(42)  # ä½¿ç”¨å›ºå®šç§å­ä»¥ä¾¿å¤ç°
    
    all_episode_data = []
    
    for episode_idx in range(num_test_episodes):
        print(f"Episode {episode_idx + 1}/{num_test_episodes}:")
        key, subkey = jax.random.split(key)
        
        episode_data = run_test_episode(
            env, policy.apply, params, subkey, 
            action_repeat, buffer_size, 
            trajectory=trajectory,  # ä¼ é€’è½¨è¿¹ç”Ÿæˆå™¨
            verbose=True
        )
        
        all_episode_data.append(episode_data)
        
        # Print episode summary
        mean_distance = np.mean(episode_data['distances'])
        min_boundary_dist = episode_data['min_boundary_distance']
        boundary_violations = episode_data['boundary_violations']
        tracking_success_rate = np.mean(np.abs(np.array(episode_data['distances']) - 1.0) < 0.3) * 100
        
        print(f"  âœ“ Completed {episode_data['num_steps']} steps")
        print(f"    Mean tracking distance: {mean_distance:.3f}m")
        print(f"    Tracking success rate (Â±30cm): {tracking_success_rate:.1f}%")
        print(f"    Min boundary distance: {min_boundary_dist:.3f}m")
        print(f"    Boundary violations: {boundary_violations} ({boundary_violations/episode_data['num_steps']*100:.1f}%)")
        print(f"    Terminated: {episode_data['terminated']}")
        print()
    
    # ==================== Aggregate Statistics ====================
    print(f"\n{'='*60}")
    print(f"Test Results:")
    print(f"{'='*60}\n")
    
    # Tracking performance
    all_distances = np.concatenate([np.array(ep['distances']) for ep in all_episode_data])
    mean_distance_all = np.mean(all_distances)
    std_distance_all = np.std(all_distances)
    tracking_success_rate_all = np.mean(np.abs(all_distances - 1.0) < 0.3) * 100
    
    print("ğŸ“Š Tracking Performance:")
    print(f"   â€¢ Mean distance to target: {mean_distance_all:.3f} Â± {std_distance_all:.3f} m")
    print(f"   â€¢ Success rate (Â±30cm from 1m): {tracking_success_rate_all:.1f}%")
    print(f"   â€¢ Min distance: {np.min(all_distances):.3f} m")
    print(f"   â€¢ Max distance: {np.max(all_distances):.3f} m")
    
    # Boundary avoidance
    total_violations = sum(ep['boundary_violations'] for ep in all_episode_data)
    total_steps = sum(ep['num_steps'] for ep in all_episode_data)
    min_boundary_distances = [ep['min_boundary_distance'] for ep in all_episode_data]
    mean_min_boundary_dist = np.mean(min_boundary_distances)
    
    print(f"\nğŸ›¡ï¸  Boundary Avoidance:")
    print(f"   â€¢ Total boundary violations: {total_violations} / {total_steps} steps")
    print(f"   â€¢ Violation rate: {total_violations/total_steps*100:.2f}%")
    print(f"   â€¢ Mean minimum boundary distance: {mean_min_boundary_dist:.3f} m")
    print(f"   â€¢ Episodes with violations: {sum(1 for ep in all_episode_data if ep['boundary_violations'] > 0)}")
    
    # Termination statistics
    num_terminated = sum(1 for ep in all_episode_data if ep['terminated'])
    num_truncated = sum(1 for ep in all_episode_data if ep['truncated'])
    
    print(f"\nğŸ“ˆ Episode Statistics:")
    print(f"   â€¢ Episode terminated early: {num_terminated} (tracking lost)")
    print(f"   â€¢ Episode completed fully: {num_truncated} (reached max steps)")
    print(f"   â€¢ Episode length: {total_steps} steps")
    
    # Overall assessment
    print(f"\n{'='*60}")
    print(f"Overall Assessment:")
    print(f"{'='*60}")
    
    tracking_passed = tracking_success_rate_all >= 70  # è‡³å°‘70%çš„æ—¶é—´åœ¨Â±30cmå†…
    boundary_passed = (total_violations / total_steps) < 0.01  # è¿è§„ç‡ä½äº1%
    
    print(f"âœ“ Tracking Test: {'PASSED âœ…' if tracking_passed else 'FAILED âŒ'}")
    print(f"  (Success rate {tracking_success_rate_all:.1f}% {'â‰¥' if tracking_passed else '<'} 70%)")
    
    print(f"âœ“ Boundary Avoidance Test: {'PASSED âœ…' if boundary_passed else 'FAILED âŒ'}")
    print(f"  (Violation rate {total_violations/total_steps*100:.2f}% {'<' if boundary_passed else 'â‰¥'} 1%)")
    
    if tracking_passed and boundary_passed:
        print(f"\nğŸ‰ All tests PASSED! The policy successfully tracks the target and avoids boundaries.")
    else:
        print(f"\nâš ï¸  Some tests FAILED. The policy needs further training or tuning.")
    
    # ==================== Visualization ====================
    print(f"\n{'='*60}")
    print(f"Generating visualizations...")
    print(f"{'='*60}\n")
    
    # Create output directory
    output_dir = 'aquila/output/trackVer11'
    os.makedirs(output_dir, exist_ok=True)
    
    # Visualize episode
    print(f"Visualizing episode...")
    save_path = f'{output_dir}/episode_1.png'
    fig = visualize_episode(
        all_episode_data[0], 
        env.boundary_half_x, 
        env.boundary_half_y, 
        env.boundary_z,
        episode_idx=1,
        save_path=save_path
    )
    plt.close(fig)
    
    # Create summary plot
    print("Creating summary plot...")
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. Distance distribution
    ax = axes[0, 0]
    ax.hist(all_distances, bins=50, alpha=0.7, color='blue', edgecolor='black')
    ax.axvline(x=1.0, color='r', linestyle='--', linewidth=2, label='Target (1m)')
    ax.axvline(x=0.7, color='orange', linestyle=':', linewidth=2, label='Acceptable Range')
    ax.axvline(x=1.3, color='orange', linestyle=':', linewidth=2)
    ax.set_xlabel('Distance to Target [m]')
    ax.set_ylabel('Frequency')
    ax.set_title('Distribution of Tracking Distances')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 2. Boundary distance distribution
    ax = axes[0, 1]
    all_boundary_distances = np.concatenate([np.array(ep['boundary_distances']) for ep in all_episode_data])
    ax.hist(all_boundary_distances, bins=50, alpha=0.7, color='green', edgecolor='black')
    ax.axvline(x=0, color='r', linestyle='--', linewidth=2, label='Boundary')
    ax.axvline(x=1.0, color='orange', linestyle=':', linewidth=2, label='Warning Zone (1m)')
    ax.set_xlabel('Distance to Boundary [m]')
    ax.set_ylabel('Frequency')
    ax.set_title('Distribution of Boundary Distances')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 3. Tracking distance over time
    ax = axes[1, 0]
    distances = np.array(all_episode_data[0]['distances'])
    ax.plot(distances, 'b-', linewidth=2, alpha=0.7)
    ax.axhline(y=1.0, color='r', linestyle='--', linewidth=2, label='Target (1m)')
    ax.axhline(y=1.3, color='orange', linestyle=':', linewidth=1, label='Acceptable Range')
    ax.axhline(y=0.7, color='orange', linestyle=':', linewidth=1)
    ax.set_xlabel('Step')
    ax.set_ylabel('Distance to Target [m]')
    ax.set_title('Tracking Distance Over Time')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 4. Boundary distance over time
    ax = axes[1, 1]
    boundary_distances = np.array(all_episode_data[0]['boundary_distances'])
    ax.plot(boundary_distances, 'g-', linewidth=2, alpha=0.7)
    ax.axhline(y=0, color='r', linestyle='--', linewidth=2, label='Boundary')
    ax.axhline(y=1.0, color='orange', linestyle=':', linewidth=1, label='Warning Zone (1m)')
    ax.set_xlabel('Step')
    ax.set_ylabel('Distance to Boundary [m]')
    ax.set_title('Boundary Distance Over Time')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    summary_path = f'{output_dir}/summary.png'
    plt.savefig(summary_path, dpi=150, bbox_inches='tight')
    print(f"  Summary plot saved to: {summary_path}")
    plt.close(fig)
    
    print(f"\nâœ… All visualizations saved to: {output_dir}/")
    print(f"\nTest completed! ğŸ‰")


if __name__ == "__main__":
    main()

